#!/usr/bin/env python
# -*- coding: utf-8 -*-

""""
Copyright (C) 2013 Co-Pierre Georg (co-pierre.georg@keble.ox.ac.uk)
Tarik Roukny Ornia (troukny@ulb.ac.be)

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, version 3 of the License.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see <http://www.gnu.org/licenses/>

The development of this software has been supported by the ERA-Net 
on Complexity through the grant RESINEE.
"""
import logging
import random

import networkx as nx


#-------------------------------------------------------------------------
#
#  class Updater
#
#-------------------------------------------------------------------------
class Updater(object):
    
    #
    # METHODS
    #
    #-------------------------------------------------------------------------
    # __init__(identifier)
    #-------------------------------------------------------------------------
    def __init__(self,  identifier):
        self.identifier = identifier
    #-------------------------------------------------------------------------
    
    
    #-------------------------------------------------------------------------
    # do_update()
    #-------------------------------------------------------------------------
    def do_update(self):
        
        #agents compute their decision
        for agent in self.environment.network.nodes():
            # first, loop over all agents
            
            # each agent is provided with a private signal
            s = random.random()
            F0s = self.environment.get_probability_density(s,  0)
            F1s = self.environment.get_probability_density(s,  1)
            print s, F0s, F1s
            
            # and the former decision of her neighbors
            neighbors_decision=[]
#            for neighbor in self.environment.network.neighbors(agent):
#                neighbors_decision.append(neighbor.previous_x)
#
#            agent.compute_decision(neighbors_decision,  F0s,  F1s)
            
            # agents compute their optimal decision x_i given the private signal and the 
            # neighborhood in the previous time-step
            
        #agents now optimize their utility function
        #for agent in self.environment.network.nodes():
       #     individual_utility=self.environment.compute_individual_utility(agent.x)
        
